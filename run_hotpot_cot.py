import joblib
import pandas as pd
import numpy as np
import json
from pathlib import Path
import asyncio

from agents.cot_agent import CoTAgentStrategy, run_cot_agent
from utils.llms import create_llm_invoker, local_llm, openai_llm
from tenacity import retry, stop_after_attempt, wait_exponential

# é…ç½®å‚æ•°
max_steps = 5
strategy = CoTAgentStrategy.COT_GT_EPM

log_file = f"output/hotpot_cot_{strategy.value}_4o_mini.log"
records_file = f"output/hotpot_cot_{strategy.value}_4o_mini.json"

# åˆ›å»º LLM è°ƒç”¨å™¨
alocal_llm = create_llm_invoker(local_llm)
aopenai_llm = create_llm_invoker(openai_llm)

inference_llm = aopenai_llm
check_llm = alocal_llm

# åŠ è½½æ•°æ®
hotpot_sample_file = "data/hotpot-qa-distractor-sample.joblib"
hotpot: pd.DataFrame = joblib.load(hotpot_sample_file).reset_index(drop=True)
print("len(hotpot):", len(hotpot))

# å¤„ç†æ”¯æŒæ€§æ®µè½
hotpot['supporting_paragraphs'] = None
for ind, row in hotpot.iterrows():
    # è·å–æ”¯æŒæ€§æ–‡ç« æ ‡é¢˜å’Œä¸Šä¸‹æ–‡ä¿¡æ¯
    supporting_articles = row['supporting_facts']['title']  # æ”¯æŒæ€§æ–‡ç« æ ‡é¢˜åˆ—è¡¨
    articles = row['context']['title']                     # æ‰€æœ‰æ–‡ç« æ ‡é¢˜
    sentences = row['context']['sentences']                # æ‰€æœ‰æ–‡ç« å¥å­

    # ğŸ¯ æå–æ”¯æŒæ®µè½
    supporting_paragraphs = []
    for article in supporting_articles:
        # ä½¿ç”¨numpy whereæ‰¾åˆ°æ–‡ç« å¯¹åº”çš„å¥å­ä½ç½®
        supporting_paragraph = ''.join(sentences[np.where(articles == article)][0])
        supporting_paragraphs.append(supporting_paragraph)

    # ç”¨æ¢è¡Œç¬¦è¿æ¥å¤šä¸ªæ”¯æŒæ®µè½
    supporting_paragraphs = '\n\n'.join(supporting_paragraphs)
    hotpot.at[ind, 'supporting_paragraphs'] = supporting_paragraphs

# ğŸ¯ ä½¿ç”¨ tenacity è£…é¥°å™¨è¿›è¡Œé‡è¯•
@retry(
    stop=stop_after_attempt(max_attempt_number=3),
    wait=wait_exponential(multiplier=1, min=1, max=10),
    before_sleep=lambda retry_state: print(f"[red]âŒ ç¬¬{retry_state.attempt_number}æ¬¡å°è¯•å¤±è´¥,ç­‰å¾…é‡è¯•...[/red]"),
    retry_error_callback=lambda retry_state: (None, str(retry_state.outcome))
)
async def run_row(row: pd.Series, ind: int):
    print("--------------------------------")
    print(f"ğŸ§  é—®é¢˜ {ind+1} : {row['question']}")
    question = row['question']
    key = row['answer']
    context = row['supporting_paragraphs']

    state = await run_cot_agent(
        question=question,
        key=key,
        context=context,
        strategy=strategy,
        action_llm=inference_llm,
        reflect_llm=inference_llm,
        judge_llm=check_llm,
        max_step=max_steps,
    )

    # æ„å»ºè®°å½•
    record = {
        "id": row['id'],
        "question": question,
        "key": key,
        "answers": [state.answer] if state.answer else [],
        "is_correct": state.is_correct,
        "step_n": state.step_n,
        "reflections": state.reflections,
        "scratchpad": state.scratchpad
    }

    # æ„å»ºæ—¥å¿—ä¿¡æ¯
    log_info = ""
    log_info += f"ğŸ§  é—®é¢˜ {ind+1} : {question}\n"
    log_info += f"ğŸ§  é—®é¢˜ {ind+1} çš„ç­”æ¡ˆ: {key}\n"
    log_info += f"ğŸ§  é—®é¢˜ {ind+1} çš„å›ç­”: {state.answer}\n"
    log_info += f"ğŸ§  å›ç­”æ˜¯å¦æ­£ç¡®: {state.is_correct}\n"
    log_info += f"ğŸ§  æ­¥æ•°: {state.step_n}\n"
    log_info += f"ğŸ§  åæ€: {state.reflections}\n"
    log_info += "\n"

    return record, log_info

async def worker(worker_id: int,
                queue: asyncio.Queue,
                answer_records: list,
                all_logs: list,
                records_file: str):
    """
    ğŸ¤– å·¥ä½œè€…åç¨‹
    """
    while True:
        try:
            # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
            ind, row = await queue.get()

            # å¤„ç†ä»»åŠ¡
            record, log_info = await run_row(row, ind)

            # æ›´æ–°ç»“æœ
            answer_records.append(record)
            all_logs.append(log_info)

            # ä¿å­˜è¿›åº¦
            with open(records_file, "w", encoding="utf-8") as f:
                json.dump(answer_records, f, ensure_ascii=False, indent=2)

            print(f"[green]âœ… å·¥ä½œè€…{worker_id}å®Œæˆç¬¬{ind+1}æ¡æ•°æ®[/green]")

            # æ ‡è®°ä»»åŠ¡å®Œæˆ
            queue.task_done()

        except asyncio.CancelledError:
            break

async def run_all():
    """
    ğŸ¯ ä¸»æ§åˆ¶æµç¨‹
    """
    # å…±äº«çŠ¶æ€
    answer_records = []
    all_logs = []

    # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
    queue = asyncio.Queue()

    # åˆ›å»ºå·¥ä½œè€…
    workers = []
    worker_num = 10
    for i in range(worker_num):
        worker_task = asyncio.create_task(
            worker(i, queue, answer_records, all_logs, records_file)
        )
        workers.append(worker_task)

    # æ·»åŠ æ‰€æœ‰ä»»åŠ¡åˆ°é˜Ÿåˆ—
    for ind, row in hotpot.iterrows():
        queue.put_nowait((ind, row))

    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    await queue.join()

    # å–æ¶ˆæ‰€æœ‰å·¥ä½œè€…
    for w in workers:
        w.cancel()
    await asyncio.gather(*workers, return_exceptions=True)

    # ä¿å­˜æœ€ç»ˆæ—¥å¿—
    with open(log_file, "w", encoding="utf-8") as f:
        f.write("\n".join(all_logs))
    print(f"[green]âœ… å·²ä¿å­˜logåˆ°{log_file}[/green]")

if __name__ == "__main__":
    asyncio.run(run_all())