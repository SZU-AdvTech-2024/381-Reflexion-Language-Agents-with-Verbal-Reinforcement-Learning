import joblib
import pandas as pd
import numpy as np

import json
from pathlib import Path
import asyncio


from agents.react_reflect_agent import ReflectionType, run_react_reflect_agent
from utils.llms import create_llm_invoker, local_llm, openai_llm
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type

max_steps = 7
trials_n = 5
strategy = ReflectionType.LAST_ATTEMPT_AND_REFLEXION

log_file = f"output/hotpot_react_reflexion_{strategy.value}_4o_mini_nostop.log"
records_file = f"output/hotpot_react_reflexion_{strategy.value}_4o_mini_nostop.json"

# alocal_llm = create_llm_invoker(local_llm, stop=["\n"])
# aopenai_llm = create_llm_invoker(openai_llm, stop=["\n"])
alocal_llm = create_llm_invoker(local_llm)
aopenai_llm = create_llm_invoker(openai_llm)


inference_llm = aopenai_llm
check_llm = alocal_llm






hotpot_sample_file = "data/hotpot-qa-distractor-sample.joblib"
hotpot: pd.DataFrame = joblib.load(hotpot_sample_file).reset_index(drop=True)
print("len(hotpot):", len(hotpot))
hotpot['supporting_paragraphs'] = None
for ind, row in hotpot.iterrows():
    # è·å–æ”¯æŒæ€§æ–‡ç« æ ‡é¢˜å’Œä¸Šä¸‹æ–‡ä¿¡æ¯
    supporting_articles = row['supporting_facts']['title']  # æ”¯æŒæ€§æ–‡ç« æ ‡é¢˜åˆ—è¡¨
    articles = row['context']['title']                     # æ‰€æœ‰æ–‡ç« æ ‡é¢˜
    sentences = row['context']['sentences']                # æ‰€æœ‰æ–‡ç« å¥å­

    # ğŸ¯ æå–æ”¯æŒæ®µè½
    # å¯¹æ¯ä¸ªæ”¯æŒæ€§æ–‡ç« ,æ‰¾åˆ°å¯¹åº”çš„å¥å­å¹¶æ‹¼æ¥æˆæ®µè½
    supporting_paragraphs = []
    for article in supporting_articles:
        # ä½¿ç”¨numpy whereæ‰¾åˆ°æ–‡ç« å¯¹åº”çš„å¥å­ä½ç½®
        # æ‹¼æ¥è¯¥æ–‡ç« çš„æ‰€æœ‰å¥å­å½¢æˆæ®µè½
        supporting_paragraph = ''.join(sentences[np.where(articles == article)][0])
        supporting_paragraphs.append(supporting_paragraph)

    # ç”¨æ¢è¡Œç¬¦è¿æ¥å¤šä¸ªæ”¯æŒæ®µè½
    supporting_paragraphs = '\n\n'.join(supporting_paragraphs)
    hotpot.at[ind, 'supporting_paragraphs'] = supporting_paragraphs




# ğŸ¯ ä½¿ç”¨ tenacity è£…é¥°å™¨è¿›è¡Œé‡è¯•
@retry(
    # æœ€å¤šé‡è¯•3æ¬¡
    stop=stop_after_attempt(max_attempt_number=3),
    # æŒ‡æ•°é€€é¿ç­–ç•¥,åˆå§‹ç­‰å¾…1ç§’,æœ€é•¿ç­‰å¾…10ç§’
    wait=wait_exponential(multiplier=1, min=1, max=10),
    # åªå¯¹ç‰¹å®šå¼‚å¸¸è¿›è¡Œé‡è¯•
    # retry=retry_if_exception_type(Exception),
    # é‡è¯•æ—¶æ‰“å°é”™è¯¯ä¿¡æ¯
    before_sleep=lambda retry_state: print(f"[red]âŒ ç¬¬{retry_state.attempt_number}æ¬¡å°è¯•å¤±è´¥,ç­‰å¾…é‡è¯•...[/red]"),
    # é‡è¯•å…¨éƒ¨å¤±è´¥åè¿”å›Noneå’Œerrorä¿¡æ¯
    retry_error_callback=lambda retry_state: (None, str(retry_state.outcome))
)
async def run_row(row: pd.Series, ind: int):
    # try:
    print("--------------------------------")
    print(f"ğŸ§  é—®é¢˜ {ind+1} : {row['question']}") # type: ignore
    question = row['question']
    key = row['answer']
    record = await run_react_reflect_agent(
        id=row['id'],
        question=question,
        key=key,
        llm=inference_llm,
        check_llm=check_llm,
        strategy=strategy,
        max_steps=max_steps,
        trials_n=trials_n
    )

    log_info = ""
    log_info += f"ğŸ§  é—®é¢˜ {ind+1} : {question}\n"
    log_info += f"ğŸ§  é—®é¢˜ {ind+1} çš„ç­”æ¡ˆ: {key}\n"
    log_info += f"ğŸ§  é—®é¢˜ {ind+1} çš„å›ç­”: {record.answers}\n"
    log_info += f"ğŸ§  å›ç­”æ˜¯å¦æ­£ç¡®: {record.is_correct}\n"
    log_info += f"ğŸ§  æ­¥æ•°: {record.step_n}\n"
    log_info += f"ğŸ§  åæ€: {record.reflections}\n"
    log_info += "\n"
    return record, log_info

async def worker(worker_id: int,
                queue: asyncio.Queue,
                answer_records: list,
                all_logs: list,
                records_file: str):
    """
    ğŸ¤– å·¥ä½œè€…åç¨‹
    """
    while True:
        try:
            # ä»é˜Ÿåˆ—è·å–ä»»åŠ¡
            ind, row = await queue.get()

            # å¤„ç†ä»»åŠ¡
            record, log_info = await run_row(row, ind)

            # æ›´æ–°ç»“æœ
            answer_records.append(record)
            all_logs.append(log_info)

            # ä¿å­˜è¿›åº¦
            records_json = [r.model_dump() if r is not None else {"error": "å¤„ç†å¤±è´¥"}
                          for r in answer_records]
            with open(records_file, "w", encoding="utf-8") as f:
                json.dump(records_json, f, ensure_ascii=False, indent=2)

            print(f"[green]âœ… å·¥ä½œè€…{worker_id}å®Œæˆç¬¬{ind+1}æ¡æ•°æ®[/green]")

            # æ ‡è®°ä»»åŠ¡å®Œæˆ
            queue.task_done()

        except asyncio.CancelledError:
            break

async def run_all():
    """
    ğŸ¯ ä¸»æ§åˆ¶æµç¨‹
    """
    output_dir = Path("output")

    # å…±äº«çŠ¶æ€
    answer_records = []
    all_logs = []

    # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
    queue = asyncio.Queue()

    # åˆ›å»ºå·¥ä½œè€…
    workers = []
    worker_num = 10
    for i in range(worker_num):
        worker_task = asyncio.create_task(
            worker(i, queue, answer_records, all_logs, records_file)
        )
        workers.append(worker_task)

    # æ·»åŠ æ‰€æœ‰ä»»åŠ¡åˆ°é˜Ÿåˆ—
    for ind, row in hotpot.iterrows():
        queue.put_nowait((ind, row))

    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
    await queue.join()

    # å–æ¶ˆæ‰€æœ‰å·¥ä½œè€…
    for w in workers:
        w.cancel()
    await asyncio.gather(*workers, return_exceptions=True)

    # ä¿å­˜æœ€ç»ˆæ—¥å¿—
    with open(log_file, "w", encoding="utf-8") as f:
        f.write("\n".join(all_logs))
    print(f"[green]âœ… å·²ä¿å­˜logåˆ°{log_file}[/green]")


if __name__ == "__main__":
    asyncio.run(run_all())
